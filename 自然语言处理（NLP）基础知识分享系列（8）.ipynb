{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad35e0e",
   "metadata": {},
   "source": [
    "## `优化代码 & 谈谈『词向量』`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb41080",
   "metadata": {},
   "source": [
    "### 让代码更好看一些\n",
    "\n",
    "在看**torchtext** 参考手册文档的时候，发现之前代码里手工编写的功能（如根据空格的分词、索引序列的截断和补齐等）已有封装函数实现，引用它的成品函数会让代码简洁一些。 \n",
    "另外将读取文件、构造语料库等前续步骤，也合并到**myDataset** 类的**__init__** 方法里。 \n",
    "\n",
    "优化后新的代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922bc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pickle \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator # 从语料迭代器构建词典 \n",
    "\n",
    "from torchtext.data.functional import simple_space_split # 语料库文本按空格分词，返回一个迭代器  \n",
    "from torchtext.data.functional import numericalize_tokens_from_iterator # 从文本序列迭代器中返回数字索引序列 \n",
    "\n",
    "from torchtext.functional import truncate # 索引序列按最大定长截断 \n",
    "from torchtext.functional import to_tensor # 索引序列按最大定长补齐（padding），并转为张量（tensor） \n",
    "\n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "MAX_LEN = 20 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc293482",
   "metadata": {},
   "source": [
    "只保留唯一1个自定义函数，用来处理训练数据中的label字段。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a67323",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = { 'unrelated' : 0 , 'agreed' : 1 , 'disagreed' : 2 } \n",
    "label_pipeline = lambda x : label_to_index [ x ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b91bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义一个DataSet 对输入数据进行预处理 \n",
    "class myDataset(Dataset): \n",
    "    def __init__(self, picked_file , max_len=20, transform=None): \n",
    "        super().__init__() \n",
    "        pkl_file_rb = open(picked_file, 'rb') \n",
    "        train =pickle.load(pkl_file_rb) \n",
    "\n",
    "        corpus = pd.concat([train.title1_tokenized, train.title2_tokenized]) \n",
    "        corpus = [c for c in corpus] \n",
    "\n",
    "        vocab = build_vocab_from_iterator(simple_space_split(corpus), min_freq=2, specials=[\"<unk>\"]) \n",
    "        # 在语料库中出现2次及以上的词汇才纳入词典，减小词典规模 \n",
    "        \n",
    "        vocab.set_default_index(-1) # 对于词典外的生词，改用-1作为index \n",
    "        self.vocab_size = vocab.__len__() # 词典大小规模  \n",
    "        \n",
    "        y_train = train.label.apply(label_pipeline) \n",
    "        \n",
    "        tensor_x = {} \n",
    "        for i in range(2): \n",
    "            x = train.title1_tokenized if i==0 else train.title2_tokenized \n",
    "            tmp_x = [] \n",
    "            ids_iter_x = numericalize_tokens_from_iterator(vocab,simple_space_split([c for c in x])) \n",
    "            for ids in ids_iter_x: \n",
    "                tmp_x.append( truncate([num for num in ids],MAX_LEN )) \n",
    "            tensor_x[i] = to_tensor(tmp_x, padding_value=0) \n",
    "\n",
    "        tensor_x = torch.stack([tensor_x[0], tensor_x[1]], 1) \n",
    "        \n",
    "        self.x = tensor_x \n",
    "        self.y = torch.from_numpy(np.asarray(y_train.values)) \n",
    "        self.transform = transform \n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.y)  # 数据集长度 \n",
    "    \n",
    "    def __getitem__(self, index): \n",
    "        x = self.x[index]  # tensor类型 \n",
    "        y = self.y[index] \n",
    "        if self.transform is not None: \n",
    "            x = self.transform(x)  # 对输入进行某些变换 \n",
    "        \n",
    "        return x, y \n",
    "\n",
    "    def get_vocab_size(self): \n",
    "        return self.vocab_size # 词典规模 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ee8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "train_data = myDataset(r'./save_file',max_len=MAX_LEN) \n",
    "vocab_size = train_data.get_vocab_size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e0cc688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  218,  1269,    32,  1178,  5971,    24,   488,  2875,   116,  5568,\n",
      "              4,  1847,     2,    13,     0,     0,     0,     0,     0,     0],\n",
      "         [  150,     8, 12895,  6168,  6345,   529,    44,    64,   740,    12,\n",
      "            488,   286, 13213,     0,     0,     0,     0,     0,     0,     0]],\n",
      "\n",
      "        [[    4,    10,    47,   677,  2561,     4,   165,    34,    17,    47,\n",
      "           5153,    62,    15,   677,  4509,  3208,    23,   284,  1185,     0],\n",
      "         [  677,  3208,  1141,   284,  1185,   677, 23975,     8,   784,  4515,\n",
      "             16, 12858,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "\n",
      "        [[    4,    10,    47,   677,  2561,     4,   165,    34,    17,    47,\n",
      "           5153,    62,    15,   677,  4509,  3208,    23,   284,  1185,     0],\n",
      "         [ 3208,  1141,   284,  1185,   677,   390,    22,   953,  9816,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "\n",
      "        [[    4,    10,    47,   677,  2561,     4,   165,    34,    17,    47,\n",
      "           5153,    62,    15,   677,  4509,  3208,    23,   284,  1185,     0],\n",
      "         [ 3299,   677,  3208,  1141,   284,  1185,   677, 23975,     8,    22,\n",
      "            953, 45212,   120,     0,     0,     0,     0,     0,     0,     0]],\n",
      "\n",
      "        [[   31,   319,  3373,  3057,     1,    94,    97,  3373,  3057,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    7,     2,   208,    15, 14291,   174,    50,  1627,   319,   122,\n",
      "           3373,  3057,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "\n",
      "        [[    4,    10,    47,   677,  2561,     4,   165,    34,    17,    47,\n",
      "           5153,    62,    15,   677,  4509,  3208,    23,   284,  1185,     0],\n",
      "         [  677,  3208,  1141,   284,  1185, 23975,     8,   381,   284,   242,\n",
      "           4515,  1670, 12858,     0,     0,     0,     0,     0,     0,     0]],\n",
      "\n",
      "        [[    7,  2220,     1,  2071,     7, 18165,  2188,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [ 2220,    78,    20,   101,   125,     7,    46,  1552,   641,     7,\n",
      "           3055,  4705,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "\n",
      "        [[    4,    10,    47,   677,  2561,     4,   165,    34,    17,    47,\n",
      "           5153,    62,    15,   677,  4509,  3208,    23,   284,  1185,     0],\n",
      "         [  677,  3208,  1141,   284,  1185,     8,   381,   284,   242,  4515,\n",
      "           1670, 12858,     0,     0,     0,     0,     0,     0,     0,     0]]]) tensor([0, 0, 0, 0, 1, 0, 0, 0])\n",
      "********************************************************************************\n",
      "torch.Size([8, 2, 20]) torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(train_data, batch_size=8, shuffle=False) \n",
    "\n",
    "for x,y in dataloader: \n",
    "    print(x,y) \n",
    "    print(\"*\"*80) \n",
    "    print(x.shape,y.shape) \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3823d5",
   "metadata": {},
   "source": [
    "我们得到了与上回同样的数据预处理结果。 \n",
    "\n",
    "上面显示的**torch.Size([8, 2, 20])** 是目前一批（8条数据）新闻标题A和B 经过数字化转换后的张量（tensor）结构。对于**tensor** 这个概念，在之后的深度学习建模中会经常提及，可以理解为多维数组。 \n",
    "这里的**[8, 2, 20]** 中，8是分批batch的大小，2代表A和B两个文档，20是每个文档中包含的词汇个数（经过截断和补齐后，已经变成等长度的）。 \n",
    "而这个多维数组中最里面存储的数据，则是每个词汇在词典中的index顺序号。 \n",
    "\n",
    "我们设想一下，直接把这个数据扔给模型去学习，是不是好呢？ \n",
    "\n",
    "显然不行，因为index 仅代表词典序，数字的大小不代表词之间语义的差别。 \n",
    "那么，如何才能表征出词所具有的语义差别呢？这便引出了「词向量」的概念。 \n",
    "\n",
    "### 谈谈『词向量』\n",
    "\n",
    "要让深度学习模型能够更好的「理解」标题序列内的词汇，我们要将它们表示成向量的形式，而不是一个单纯数字。\n",
    "所以现在的问题变成： \n",
    "「要怎么将一个词汇表示成一个N 维向量？」 \n",
    "\n",
    "为了便于演示和理解，我们把N设定为2，这样可以在平面图中示例： \n",
    "![这是图片](imgs/Unsupervised_Learning_Word_Embedding_1440-03.png \"Word_Embedding\")\n",
    "\n",
    "在这个2 维空间里头，我们可以发现一个好的词向量表示有2 个特性： \n",
    "•\t距离有意义：「dog」与意思相近的词汇「cat」距离接近，而与较不相关的「flower」距离较远 \n",
    "•\t维度有意义：仔细观察，我们发现横轴可以解释为不同的词性（动词 VS 名词）；纵轴可以解释为与运动相关程度 \n",
    "\n",
    "如果我们能把语料库里头的每个词汇都表示成像这样有意义的词向量，模型就能帮我们找到潜藏在大量词汇中的语义关系，并进一步改善NLP 任务的精准度。 \n",
    "大部分的情况我们并不需要自己手动设定每个词汇的词向量。我们可以随机初始化所有词向量，并利用平常训练模型的反向传播算法（Backpropagation），自动学到一组适合当前NLP 任务的理想的词向量。这种技术也被称之为词嵌入（Word Embedding）。 \n",
    "\n",
    "在**PyTorch** 中，可以使用**torch.nn.Embedding** 层来帮我们做到这件事情： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "207b2182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.3216, -0.0349, -0.8415,  0.4328],\n",
      "          [-0.2446, -0.7660, -0.1314,  0.5798],\n",
      "          [-0.5807, -0.4590, -0.2667,  0.2735],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0856,  0.6362, -0.1089, -0.7590],\n",
      "          [ 0.2191, -0.3605,  0.6859,  0.5929],\n",
      "          [ 0.1359,  0.4224,  0.8961,  0.0097],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9065,  0.0611,  0.3347,  0.2499],\n",
      "          [-0.5257, -0.4218,  0.0394,  0.7377],\n",
      "          [-0.1322,  0.6302,  0.7646, -0.0280],\n",
      "          ...,\n",
      "          [ 0.6432,  0.6028,  0.1835, -0.4351],\n",
      "          [-0.4235, -0.7525,  0.2486,  0.4388],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0733,  0.8526,  0.3267, -0.0788],\n",
      "          [ 0.8529,  0.3061,  0.4096, -0.1053],\n",
      "          [ 0.6355,  0.4800, -0.6012, -0.0656],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9065,  0.0611,  0.3347,  0.2499],\n",
      "          [-0.5257, -0.4218,  0.0394,  0.7377],\n",
      "          [-0.1322,  0.6302,  0.7646, -0.0280],\n",
      "          ...,\n",
      "          [ 0.6432,  0.6028,  0.1835, -0.4351],\n",
      "          [-0.4235, -0.7525,  0.2486,  0.4388],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.8529,  0.3061,  0.4096, -0.1053],\n",
      "          [ 0.6355,  0.4800, -0.6012, -0.0656],\n",
      "          [ 0.6432,  0.6028,  0.1835, -0.4351],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.9065,  0.0611,  0.3347,  0.2499],\n",
      "          [-0.5257, -0.4218,  0.0394,  0.7377],\n",
      "          [-0.1322,  0.6302,  0.7646, -0.0280],\n",
      "          ...,\n",
      "          [ 0.6432,  0.6028,  0.1835, -0.4351],\n",
      "          [-0.4235, -0.7525,  0.2486,  0.4388],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0733,  0.8526,  0.3267, -0.0788],\n",
      "          [ 0.8529,  0.3061,  0.4096, -0.1053],\n",
      "          [ 0.6355,  0.4800, -0.6012, -0.0656],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1606, -0.0126,  0.8301, -0.5338],\n",
      "          [-0.5255,  0.2322, -0.3078,  0.7584],\n",
      "          [ 0.2719, -0.0936, -0.9010,  0.3250],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.5255,  0.2322, -0.3078,  0.7584],\n",
      "          [ 0.6682, -0.1490,  0.5041,  0.5265],\n",
      "          [ 0.3344, -0.0973, -0.6929,  0.6313],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9065,  0.0611,  0.3347,  0.2499],\n",
      "          [-0.5257, -0.4218,  0.0394,  0.7377],\n",
      "          [-0.1322,  0.6302,  0.7646, -0.0280],\n",
      "          ...,\n",
      "          [ 0.6432,  0.6028,  0.1835, -0.4351],\n",
      "          [-0.4235, -0.7525,  0.2486,  0.4388],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0733,  0.8526,  0.3267, -0.0788],\n",
      "          [ 0.8529,  0.3061,  0.4096, -0.1053],\n",
      "          [ 0.6355,  0.4800, -0.6012, -0.0656],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "********************************************************************************\n",
      "torch.Size([8, 2, 20, 4])\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataloader: \n",
    "    embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=4,\\\n",
    "                                   padding_idx=0, max_norm=True) \n",
    "    print(embedding(x)) \n",
    "    print(\"*\"*80) \n",
    "    print(embedding(x).shape) \n",
    "    break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9658411",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "好了，就到这儿吧。 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
