{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec78705",
   "metadata": {},
   "source": [
    "## `使用LSI（潜在语义索引）进行维度归约` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e59550",
   "metadata": {},
   "source": [
    "对于之前训练的TF-IDF向量空间表示，我们重新跑一遍代码，看一下它有些什么特点。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eca9a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<320552x67243 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2503463 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pickle \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    " \n",
    "pkl_file_rb = open(r'./save_file', 'rb') \n",
    "train =pickle.load(pkl_file_rb) \n",
    " \n",
    "corpus = pd.concat([train . title1_tokenized, train . title2_tokenized]) \n",
    "corpus = [c for c in corpus] \n",
    " \n",
    "tfidf_model = TfidfVectorizer().fit(corpus) \n",
    "\n",
    "matrix1= tfidf_model.transform(train['title1_tokenized']) \n",
    "matrix2= tfidf_model.transform(train['title2_tokenized']) \n",
    "\n",
    "matrix1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66857c25",
   "metadata": {},
   "source": [
    "有没有注意到——它被存成了一个 **sparse matrix** 的数据类型。 \n",
    "为什么会这样？ \n",
    "我们看到词库有67243个，这也是向量空间的维数，而一个新闻标题充其量也只由十几个词构成，因此绝大多数的维上取值都是0！ \n",
    "事实上，从内存供给能力看，也只能用这种稀疏矩阵的方法存储，否则就会OOM了…… \n",
    "\n",
    "对于这种高维稀疏的数据，使用机器学习（Machine Learning）直接用来训练模型是不合适的。 \n",
    "一方面，如此高的维度将导致低效的计算；另一方面，高维稀疏数据会增加从文本挖掘潜在模式的难度。 \n",
    "\n",
    "维度归约，也称降维，是指使用数据编码或变换，以便得到原数据的归约或“压缩”表示。 \n",
    "如果原数据可以由压缩数据重新构造而不丢失任何信息，则该数据归约是无损的；如果我们只能重新构造原数据的近似表示，则该数据归约是有损的。 \n",
    "![这是图片](imgs/R-C.png \"dimensionality reduction\")\n",
    "\n",
    "### LSI（潜在语义索引）\n",
    "\n",
    "潜在语义索引（LSI）是一种常用的文档维度归约算法。LSI基于奇异值分解（Singular Value Decomposition，SVD）的方法实现，SVD是线性代数中一种重要的矩阵分解，是矩阵分析中正规矩阵对角化的推广。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157b0d7",
   "metadata": {},
   "source": [
    "LSI基本思想:提取最具代表性的特征，同时最小化同构错误。 \n",
    "奇异值分解(SVD)：X=(Aij)=UΣV\\`, \n",
    "\t\t其中，Xm\\*n, Um\\*r, Σr\\*r(对角阵), Vn\\*r, r<=MIN(m,n), \n",
    "取Σ对角上的前k个元素，得Σk, \n",
    "Xk= UkΣkVk\\`, Uk由U的前k列组成，Vk由V的前k列组成, \n",
    "文档d在LSI对应的向量d’=dTUkΣ-1 ，由r维降至k维。 \n",
    "\n",
    "![这是图片](imgs/svd.jpg \"SVD & LSI\")\n",
    "\n",
    "我们可以使用 **sklearn** 包的 **TruncatedSVD** 函数实现LSI方法。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6423edc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=64, n_iter=100, random_state=122)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd_model = TruncatedSVD(n_components=64, algorithm='randomized', n_iter=100, random_state=122) #参数n_components即降维的目标维数r \n",
    "svd_model.fit(tfidf_model.transform(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee934494",
   "metadata": {},
   "source": [
    "这里我们指定了降维的目标维数r为64，也就是说相对于原始的TF-IDF模型，我们把数据有损压缩了1000倍！ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c68fd521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320552, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用这个模型，对TF-IDF结果进行压缩。 \n",
    "matrix1_sub  = svd_model.transform(matrix1) \n",
    "matrix2_sub  = svd_model.transform(matrix2) \n",
    "matrix1_sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d98cee8",
   "metadata": {},
   "source": [
    "### 压缩1000倍的数据还有用么？\n",
    "\n",
    "接下来，我们使用这个压缩的“稠密”数据重复一下上一回的余弦相似度分布计算。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "731260e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    " \n",
    "def cos_sim(a, b): \n",
    "    a_norm = np.linalg.norm(a) \n",
    "    b_norm = np.linalg.norm(b) \n",
    "    cos = np.dot(a,b)/(a_norm * b_norm) \n",
    "    return cos \n",
    "\n",
    "cosin_measure = [] \n",
    "for i in range(matrix1_sub.shape[0]): \n",
    "    cosin_measure.append(cos_sim(np.squeeze(matrix1_sub[i]),np.squeeze(matrix2_sub[i]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9603bd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns with null values:\n",
      " title1_zh            0\n",
      "title2_zh            7\n",
      "label                0\n",
      "title1_tokenized     0\n",
      "title2_tokenized     0\n",
      "cosin_measure       18\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train['cosin_measure'] = cosin_measure \n",
    "print('Train columns with null values:\\n', train.isnull().sum()) #检查各列的空值记录数 \n",
    "\n",
    "train.loc[:,'cosin_measure'] = train.loc[:,'cosin_measure'].fillna(0) #余弦相似度空值填充 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38e551d",
   "metadata": {},
   "source": [
    "简便起见，我们跳过4分位箱形图的展示，直接看一下不同label在百分位数分布点位[1,5,10,25,50,75,90,95,99]的余弦相似度取值。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f46fc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unrelated [-0.06352342 -0.01780777 -0.00228008  0.04328785  0.25206004  0.66588372\n",
      "  0.88882218  0.96387027  0.99633213]\n",
      "agreed [0.03268588 0.15247196 0.26748694 0.54153524 0.80297221 0.96769122\n",
      " 0.99764079 0.99989671 1.        ]\n",
      "disagreed [0.00746681 0.04532879 0.08774524 0.21708    0.43988834 0.70170525\n",
      " 0.85775077 0.91423598 0.97046834]\n"
     ]
    }
   ],
   "source": [
    "for level in ['unrelated','agreed','disagreed']: \n",
    "    data = train[train.label == level].cosin_measure \n",
    "    print(level,np.percentile(data, [1,5,10,25,50,75,90,95,99], axis=0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9407ba",
   "metadata": {},
   "source": [
    "我们看到，不同label类别的新闻标题A和B余弦相似度的取值分布，仍然保留了一定的差异。 \n",
    "\n",
    "对于新版的余弦相似度，我们选用0.888这个吉祥的数字作为分界阈值，即：**新闻标题A和B余弦相似度小于0.888的判为'unrelated'，余弦相似度大于0.888的判为'agreed'。**  \n",
    "\n",
    "重新计算一下准确率。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9a43356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 72.9%\n"
     ]
    }
   ],
   "source": [
    "train_currect = train[(train['label'] == 'unrelated') & (train['cosin_measure'] < 0.888) \\\n",
    "                      | (train['label'] == 'agreed') & (train['cosin_measure'] >= 0.888)] \n",
    "accuracy = len(train_currect) / len(train) \n",
    "print('accuracy: {:.1%}'.format(accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fca2a0",
   "metadata": {},
   "source": [
    "结果是<font color=\"#dd0000\">72.9%</font>，比之前的<font color=\"#dd0000\">77.4%</font>有所下降，但与基线模型的<font color=\"#dd0000\">68%</font>相比，依然有所提升！ \n",
    "这里仅是通过简单的余弦距离方法利用LSI向量数据，下一次我们将尝试使用这个64维的压缩数据建立一个机器学习（Machine Learning）模型用来识别新闻标题A和B的关系。 \n",
    "\n",
    "---\n",
    "好了，就到这儿吧。 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
